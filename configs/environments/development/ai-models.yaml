# Apollo Platform - Development AI Models Configuration
# ===========================================================

environment: development

# AI Model Provider Configuration
providers:
  openrouter:
    enabled: true
    base_url: https://openrouter.ai/api/v1
    api_key: ${OPENROUTER_API_KEY}
    timeout: 60000
    max_retries: 3

    models:
      - id: anthropic/claude-3.5-sonnet
        name: Claude 3.5 Sonnet
        cost_per_1k_tokens: 0.015
        max_tokens: 200000
        use_cases: [analysis, intelligence, reasoning]

      - id: openai/gpt-4-turbo
        name: GPT-4 Turbo
        cost_per_1k_tokens: 0.01
        max_tokens: 128000
        use_cases: [analysis, generation, coding]

      - id: google/gemini-pro-1.5
        name: Gemini Pro 1.5
        cost_per_1k_tokens: 0.007
        max_tokens: 1000000
        use_cases: [document_analysis, long_context]

  openai:
    enabled: true
    base_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY}
    organization: null
    timeout: 60000
    max_retries: 3

    models:
      - id: gpt-4-turbo-preview
        name: GPT-4 Turbo
        cost_per_1k_tokens: 0.01
        max_tokens: 128000
        use_cases: [analysis, reasoning]

      - id: gpt-3.5-turbo
        name: GPT-3.5 Turbo
        cost_per_1k_tokens: 0.0005
        max_tokens: 16385
        use_cases: [quick_analysis, classification]

  anthropic:
    enabled: true
    base_url: https://api.anthropic.com/v1
    api_key: ${ANTHROPIC_API_KEY}
    timeout: 60000
    max_retries: 3

    models:
      - id: claude-3-opus-20240229
        name: Claude 3 Opus
        cost_per_1k_tokens: 0.015
        max_tokens: 200000
        use_cases: [deep_analysis, investigation]

      - id: claude-3-sonnet-20240229
        name: Claude 3 Sonnet
        cost_per_1k_tokens: 0.003
        max_tokens: 200000
        use_cases: [general_analysis, balanced]

      - id: claude-3-haiku-20240307
        name: Claude 3 Haiku
        cost_per_1k_tokens: 0.00025
        max_tokens: 200000
        use_cases: [quick_tasks, classification]

  google:
    enabled: true
    base_url: https://generativelanguage.googleapis.com/v1beta
    api_key: ${GOOGLE_AI_API_KEY}
    timeout: 60000
    max_retries: 3

    models:
      - id: gemini-1.5-pro
        name: Gemini 1.5 Pro
        cost_per_1k_tokens: 0.007
        max_tokens: 1000000
        use_cases: [document_analysis, multimodal]

      - id: gemini-1.5-flash
        name: Gemini 1.5 Flash
        cost_per_1k_tokens: 0.0001
        max_tokens: 1000000
        use_cases: [fast_processing, high_volume]

  deepseek:
    enabled: true
    base_url: https://api.deepseek.com/v1
    api_key: ${DEEPSEEK_API_KEY}
    timeout: 60000
    max_retries: 3

    models:
      - id: deepseek-chat
        name: DeepSeek Chat
        cost_per_1k_tokens: 0.0001
        max_tokens: 32000
        use_cases: [cost_effective, reasoning]

      - id: deepseek-coder
        name: DeepSeek Coder
        cost_per_1k_tokens: 0.0001
        max_tokens: 32000
        use_cases: [code_analysis, technical]

  groq:
    enabled: true
    base_url: https://api.groq.com/openai/v1
    api_key: ${GROQ_API_KEY}
    timeout: 30000
    max_retries: 3

    models:
      - id: llama-3.1-70b-versatile
        name: Llama 3.1 70B
        cost_per_1k_tokens: 0.0001
        max_tokens: 32000
        use_cases: [fast_inference, real_time]

      - id: mixtral-8x7b-32768
        name: Mixtral 8x7B
        cost_per_1k_tokens: 0.0001
        max_tokens: 32768
        use_cases: [multilingual, fast]

# Model routing strategies
routing:
  # Intelligence analysis routing
  intelligence_analysis:
    strategy: quality_first
    primary: anthropic/claude-3-opus-20240229
    fallback:
      - anthropic/claude-3-sonnet-20240229
      - openai/gpt-4-turbo-preview
    cost_limit: 1.00  # dollars per request

  # Quick classification tasks
  classification:
    strategy: cost_optimized
    primary: groq/llama-3.1-70b-versatile
    fallback:
      - openai/gpt-3.5-turbo
      - anthropic/claude-3-haiku-20240307
    cost_limit: 0.01

  # Document analysis
  document_analysis:
    strategy: context_optimized
    primary: google/gemini-1.5-pro
    fallback:
      - anthropic/claude-3-sonnet-20240229
      - openai/gpt-4-turbo-preview
    cost_limit: 0.50

  # Real-time processing
  real_time:
    strategy: speed_first
    primary: groq/llama-3.1-70b-versatile
    fallback:
      - groq/mixtral-8x7b-32768
      - google/gemini-1.5-flash
    cost_limit: 0.10

  # Code analysis
  code_analysis:
    strategy: specialized
    primary: deepseek/deepseek-coder
    fallback:
      - openai/gpt-4-turbo-preview
      - anthropic/claude-3-sonnet-20240229
    cost_limit: 0.25

# Use case specific configurations
use_cases:
  # Facial recognition AI enhancement
  facial_recognition_enhancement:
    enabled: true
    model: anthropic/claude-3-sonnet-20240229
    temperature: 0.1
    max_tokens: 1000
    system_prompt: "You are an AI assistant helping with facial recognition analysis for law enforcement. Analyze facial features and provide detailed descriptions."

  # Voice analysis
  voice_analysis:
    enabled: true
    model: anthropic/claude-3-sonnet-20240229
    temperature: 0.2
    max_tokens: 2000
    system_prompt: "You are an AI assistant analyzing voice patterns and speech characteristics for investigative purposes."

  # OSINT data analysis
  osint_analysis:
    enabled: true
    model: anthropic/claude-3-opus-20240229
    temperature: 0.3
    max_tokens: 4000
    system_prompt: "You are an intelligence analyst processing OSINT data. Identify patterns, connections, and actionable intelligence."

  # Financial transaction analysis
  financial_analysis:
    enabled: true
    model: anthropic/claude-3-opus-20240229
    temperature: 0.1
    max_tokens: 8000
    system_prompt: "You are a financial crimes investigator analyzing transactions, identifying money laundering patterns, and tracking illicit funds."

  # Blockchain analysis
  blockchain_analysis:
    enabled: true
    model: openai/gpt-4-turbo-preview
    temperature: 0.2
    max_tokens: 4000
    system_prompt: "You are a blockchain investigator analyzing cryptocurrency transactions, wallet addresses, and blockchain patterns."

  # Social media analysis
  social_media_analysis:
    enabled: true
    model: anthropic/claude-3-sonnet-20240229
    temperature: 0.3
    max_tokens: 4000
    system_prompt: "You are an OSINT analyst processing social media data to identify connections, patterns, and intelligence."

  # Threat assessment
  threat_assessment:
    enabled: true
    model: anthropic/claude-3-opus-20240229
    temperature: 0.2
    max_tokens: 4000
    system_prompt: "You are a threat analyst assessing risk levels, identifying vulnerabilities, and providing security recommendations."

  # Document summarization
  document_summarization:
    enabled: true
    model: google/gemini-1.5-flash
    temperature: 0.4
    max_tokens: 2000
    system_prompt: "You are a document analyst. Summarize key information, extract important details, and identify relevant patterns."

  # Relationship mapping
  relationship_mapping:
    enabled: true
    model: anthropic/claude-3-opus-20240229
    temperature: 0.2
    max_tokens: 8000
    system_prompt: "You are an intelligence analyst mapping relationships between entities, identifying networks, and uncovering connections."

  # Predictive analysis
  predictive_analysis:
    enabled: true
    model: anthropic/claude-3-opus-20240229
    temperature: 0.3
    max_tokens: 4000
    system_prompt: "You are a predictive analyst using historical data to forecast behavior, identify patterns, and predict likely outcomes."

# Prompt templates
prompts:
  analyze_intelligence:
    template: |
      Analyze the following intelligence data for case: {case_id}
      Target: {target_name}

      Data:
      {intelligence_data}

      Provide:
      1. Key findings
      2. Identified patterns
      3. Actionable intelligence
      4. Recommended next steps
      5. Confidence level (0-100%)

  financial_pattern_detection:
    template: |
      Analyze these financial transactions for suspicious patterns:

      Transactions:
      {transactions}

      Known entities:
      {known_entities}

      Identify:
      1. Money laundering indicators
      2. Shell company usage
      3. Transaction patterns
      4. Geographic routing
      5. Risk assessment

  social_media_sentiment:
    template: |
      Analyze social media posts for sentiment and intelligence:

      Posts:
      {posts}

      Provide:
      1. Overall sentiment
      2. Key topics
      3. Behavioral indicators
      4. Network connections
      5. Urgency assessment

  threat_scoring:
    template: |
      Score the following threat based on available intelligence:

      Threat data:
      {threat_data}

      Provide:
      1. Overall threat score (0-100)
      2. Risk factors
      3. Mitigation recommendations
      4. Timeline assessment
      5. Required resources

# Performance settings
performance:
  # Request pooling
  pooling:
    enabled: true
    max_pool_size: 10
    min_pool_size: 2
    idle_timeout: 30000

  # Caching
  caching:
    enabled: true
    ttl: 3600  # 1 hour
    max_size: 1000

  # Rate limiting
  rate_limiting:
    enabled: false  # Disabled in dev
    max_requests_per_minute: 60
    burst_size: 10

  # Timeout settings
  timeouts:
    connection: 10000
    request: 60000
    total: 120000

# Cost management
cost_management:
  enabled: true
  daily_limit: 50.00  # dollars
  monthly_limit: 1000.00  # dollars
  alert_threshold: 0.8  # 80% of limit

  tracking:
    enabled: true
    log_all_requests: true
    export_to_database: true

# Development features
development:
  mock_mode: false
  log_prompts: true
  log_responses: true
  save_conversations: true
  conversation_dir: c:/SECURE_THREAT_INTEL/YoureGunnaHAveToShootMeToStopME/apollo/data/dev/conversations

  # Testing
  test_mode: false
  test_responses:
    enabled: false

# Monitoring
monitoring:
  enabled: true
  metrics:
    - request_count
    - response_time
    - token_usage
    - cost_per_request
    - error_rate
    - model_performance

  logging:
    level: debug
    log_file: c:/SECURE_THREAT_INTEL/YoureGunnaHAveToShootMeToStopME/apollo/logs/dev/ai-models.log
